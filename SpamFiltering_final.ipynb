{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dataset and declaring variables\n",
    "dataset = \"dreaddit-train.csv\"\n",
    "posts = []\n",
    "tokens = []\n",
    "tags = []\n",
    "spam_indices = []\n",
    "not_spam_indices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spam_filtering():\n",
    "    \n",
    "    #reading the dataset\n",
    "    dataframe = pd.read_csv(dataset) \n",
    "    \n",
    "    #appending individual posts\n",
    "    for text in dataframe.text:\n",
    "        posts.append(text)\n",
    "        \n",
    "    #tokenization of words in posts\n",
    "    for post in posts:  \n",
    "        tokens.append(word_tokenize(post))\n",
    "    \n",
    "    #Part-of-speech tagging of individual words\n",
    "    for i in range(0,len(tokens)):\n",
    "        tags.append(nltk.pos_tag(tokens[i]))\n",
    "    \n",
    "    #initializing propoer nouns list\n",
    "    total_posts = len(tags)\n",
    "    prp_flag = [0] * total_posts\n",
    "    \n",
    "    \n",
    "    for i in range(0, len(tags)):\n",
    "        flag = 0\n",
    "        for word in tags[i]:\n",
    "            if word[1] == 'PRP':   #if word tagged as proper noun,then flag value is one\n",
    "                flag = 1\n",
    "                break\n",
    "            \n",
    "        if flag==1:\n",
    "            prp_flag[i] = flag   #append flag values for all posts containing one or more words with flag value as one\n",
    "            \n",
    "    for i in range(0,len(prp_flag)):\n",
    "        if prp_flag[i] == 0:\n",
    "            spam_indices.append(i)      #append posts with flag value as zero as spam posts\n",
    "        else:\n",
    "            not_spam_indices.append(i)  #append posts with flag value as one as non-spam posts\n",
    "            \n",
    "    \n",
    "    #creation of two separate dataframes by dropping umimportant columns\n",
    "    spam_df = dataframe.drop(dataframe.index[not_spam_indices])\n",
    "    filtered_df = dataframe.drop(dataframe.index[spam_indices])\n",
    "    \n",
    "    #Convertion to csv format\n",
    "    spam_df.to_csv(\"Spam-Posts.csv\")\n",
    "    filtered_df.to_csv(\"Filtered-Posts.csv\")\n",
    "    \n",
    "spam_filtering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
